{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 《Poly-encoders:Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring 》\n",
    "#### 作者：Samuel Humeau,  Jason Weston\n",
    "#### 单位：Facebook\n",
    "#### 发表会议及时间：ICLR 2020\n",
    "\n",
    "---\n",
    "\n",
    "### 论文主题：文本匹配\n",
    "### 授课老师：himon\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 前言\n",
    "### 1.1 上节课内容回顾\n",
    "\n",
    "\n",
    "\n",
    "### <font color='orange'>主要内容：</font>\n",
    "\n",
    "<div>\n",
    "<img src='ima_1.png' width='500' height='500'/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='orange'>主要知识点： </font>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='bac.png' width='700' height='700'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型回顾\n",
    "\n",
    "\n",
    "### <font color='orange'>BERT： </font>\n",
    "\n",
    "---\n",
    "\n",
    "<div>\n",
    "<img src='bert2.png' width='800' height='800'/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div>\n",
    "<img src='bert1.png' width='800' height='800'/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='orange'>bi-encoder:</font>\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='bi.png' width='600' height='600'/>\n",
    "</div>\n",
    "\n",
    "--- \n",
    "\n",
    "### <font color='orange'>cross-encoder:</font>\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='cross.png' width='600' height='600'/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='orange'>poly-encoder:</font>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='poly.png' width='600' height='600'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 本课知识树\n",
    "\n",
    "\n",
    "### <font color='orange'>本课目标 </font>：\n",
    "\n",
    "1. <font color='green'>BERT模型实现和讲解 </font>\n",
    "2. <font color='green'> Transformer模型实现和讲解</font>\n",
    "3. <font color='green'>Bi-encoder，Cross-encoder，Poly-encoder模型实现和讲解 </font>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='knw.png' width='900' height='900'/>\n",
    "</div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 准备工作\n",
    "### 3.1 项目环境配置\n",
    "- Python3.7\n",
    "- jupyter notebook\n",
    "\n",
    "\n",
    "项目依赖：\n",
    "\n",
    "- torch (1.7.0+cpu)\n",
    "- tqdm (4.51.0)\n",
    "- nltk (3.5)\n",
    "- numpy (1.19.2)\n",
    "- scikit-learn (0.23.2)\n",
    "- tensorboardX (2.1)\n",
    "- transformers（4.3.2）\n",
    "\n",
    "###  3.2 数据集下载\n",
    "\n",
    "Quora DataSet:  https://drive.google.com/file/d/0B0PlTAo--BnaQWlsZl9FZ3l1c28/view?usp=sharing\n",
    "\n",
    "###  3.3 预训练模型下载\n",
    "\n",
    "BERT预训练模型：https://huggingface.co/google  \n",
    "课堂使用模型： bert_uncased_L-4_H-256_A-4  \n",
    "\n",
    "config：\n",
    "\n",
    "```\n",
    "{\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 256,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 1024,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"model_type\": \"bert\",\n",
    "  \"num_attention_heads\": 4,\n",
    "  \"num_hidden_layers\": 4,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"type_vocab_size\": 2,\n",
    "  \"vocab_size\": 30522\n",
    "}\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.BERT-PyTorch实现\n",
    "\n",
    "见 Bert.ipynb\n",
    "\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  huggingface Transformers使用\n",
    "\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "# 加载 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/Users/himon/Jobs/class/paper7/part3/Poly-Encoder/bert_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "model = BertModel.from_pretrained(\"/Users/himon/Jobs/class/paper7/part3/Poly-Encoder/bert_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造输入tensor\n",
    "inputs = tokenizer( [\"We are very happy to show you the Transformers library.\", \"We hope you don't hate it.\"],\n",
    "                   padding=True, max_length=512, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 19081, 3075, 1012, 102], [101, 2057, 3246, 2017, 2123, 1005, 1056, 5223, 2009, 1012, 102, 0, 0]]\n",
      "token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in inputs.items():\n",
    " print(f\"{key}: {value.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得输出\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)\n",
    "# 1.  encoder 最后一层输出的隐藏状态序列，(batch_size, sequence_length, hidden_size)\n",
    "# 2. 对输出序列进行pool操作的结果，(batch_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2098, -0.2416,  1.6344,  ..., -0.8214, -1.0616, -0.2032],\n",
       "         [-1.1998,  0.3049, -0.2696,  ..., -0.4347, -1.2940,  0.3206],\n",
       "         [-1.0728,  0.6434,  0.2169,  ...,  0.7372,  0.2351, -0.1023],\n",
       "         ...,\n",
       "         [-0.5342,  1.7851,  0.8415,  ..., -0.4030, -0.9626, -0.1490],\n",
       "         [-0.9382,  0.3895,  1.7330,  ...,  0.2567, -0.2759,  0.3235],\n",
       "         [-0.2864, -0.1061,  1.4104,  ..., -1.2576, -0.3859,  0.1968]],\n",
       "\n",
       "        [[-1.2128, -0.1443,  0.5295,  ..., -0.1157, -0.7186,  0.1493],\n",
       "         [-2.1433,  0.1393, -0.6502,  ..., -0.4060, -0.3045,  0.2669],\n",
       "         [-0.8939,  0.5799,  0.1188,  ..., -0.8029,  0.4832,  0.1352],\n",
       "         ...,\n",
       "         [-1.2384,  0.8889, -0.9261,  ..., -1.2058,  1.0169,  0.2655],\n",
       "         [-2.9402,  0.7719, -0.0965,  ...,  0.3473, -0.7344,  0.7664],\n",
       "         [-3.3332,  1.3093, -0.3994,  ..., -0.0325, -0.4493,  0.7918]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-9.8951e-01,  4.5933e-02, -9.9730e-01, -9.1627e-02,  2.0311e-01,\n",
       "          9.4935e-01, -1.3578e-01,  6.7193e-02,  4.8439e-02,  9.9386e-01,\n",
       "          2.1417e-01,  9.9710e-01, -9.9997e-01, -8.9472e-01, -7.6646e-01,\n",
       "         -1.7137e-01,  9.9812e-01, -8.1271e-01,  9.9768e-01, -9.9797e-01,\n",
       "         -1.0000e+00,  9.8953e-01,  9.4890e-01, -8.4299e-01,  9.9157e-01,\n",
       "          9.9823e-01, -1.3508e-01,  2.1450e-01,  8.6181e-01,  4.6731e-02,\n",
       "         -9.0461e-01, -1.1977e-01,  8.3446e-01, -9.9549e-01, -9.9989e-01,\n",
       "         -9.9751e-01, -1.2010e-01,  9.5225e-01, -3.8822e-01,  3.2415e-01,\n",
       "          5.6063e-01, -7.3138e-01, -1.9580e-01,  9.7404e-01,  9.9656e-01,\n",
       "          1.9087e-01,  5.0993e-01,  9.9225e-01,  1.0948e-01,  1.4929e-01,\n",
       "          1.4218e-01, -5.4194e-01,  7.8738e-02,  9.9999e-01, -9.9376e-01,\n",
       "         -6.7545e-01,  9.7172e-01,  9.9970e-01, -2.8755e-01, -9.9776e-01,\n",
       "         -9.9992e-01,  9.9990e-01,  9.8388e-01, -1.2694e-01, -4.3925e-01,\n",
       "          3.7969e-01, -4.6106e-02, -9.6379e-01, -2.6796e-01,  4.3973e-03,\n",
       "          8.7808e-02,  1.7539e-01, -6.3815e-01,  9.9697e-01, -3.2261e-01,\n",
       "         -7.5737e-01,  9.9877e-01, -5.5073e-01,  6.3992e-01,  5.3865e-01,\n",
       "         -9.8026e-01, -3.8123e-03,  9.1491e-01,  7.1040e-02, -2.0812e-02,\n",
       "         -5.2258e-01, -1.3574e-01,  9.9991e-01, -7.7559e-01, -9.9890e-01,\n",
       "          9.9934e-01, -9.8904e-01,  7.9239e-01, -1.1377e-01, -9.9505e-01,\n",
       "         -9.9500e-01,  1.0408e-01, -3.1071e-01,  9.6064e-01,  2.6956e-02,\n",
       "         -9.9550e-01,  3.5953e-01, -9.9359e-01, -1.6974e-01, -7.8533e-01,\n",
       "         -1.5930e-01, -9.9997e-01, -9.5374e-01,  1.0222e-01,  9.7128e-02,\n",
       "         -3.3210e-02,  1.5472e-01,  2.9763e-02,  1.1128e-01, -1.1093e-01,\n",
       "         -8.5964e-02,  9.9126e-01, -9.8795e-01, -9.9664e-01,  1.4935e-01,\n",
       "         -9.9816e-01, -9.9963e-01, -1.9765e-01,  6.6938e-01,  9.9462e-01,\n",
       "          2.2056e-01, -8.6580e-01, -9.9733e-01,  1.0692e-02, -9.8820e-01,\n",
       "         -7.2713e-03,  3.8332e-02, -1.0103e-01,  5.9082e-01, -7.8867e-01,\n",
       "         -9.8868e-01, -9.9027e-01,  9.9708e-01, -8.8214e-01, -3.1799e-02,\n",
       "          7.7368e-01,  8.5027e-02, -7.0821e-01,  3.1866e-01,  9.6088e-01,\n",
       "         -9.9881e-01, -9.9985e-01,  9.9999e-01,  9.9997e-01, -8.5634e-01,\n",
       "          9.9985e-01, -9.3101e-01, -9.9995e-01,  9.7286e-01, -8.2927e-01,\n",
       "         -6.8998e-03,  9.9994e-01, -5.1302e-02,  6.3761e-02,  9.5383e-01,\n",
       "         -9.9993e-01, -7.7959e-01,  5.1928e-01, -7.5959e-01, -8.4035e-01,\n",
       "         -9.7854e-01, -6.9034e-03,  9.3088e-01, -9.9758e-01,  1.0695e-02,\n",
       "         -9.8521e-01,  9.9934e-01, -5.7285e-01,  1.1208e-02, -5.8045e-02,\n",
       "          9.5436e-02,  9.9393e-01, -9.6532e-01, -8.2899e-02,  2.9547e-02,\n",
       "          9.6386e-01,  1.1443e-01,  6.8800e-02, -9.9984e-01,  9.9994e-01,\n",
       "         -9.1117e-01,  9.9970e-01,  9.9870e-01, -7.5017e-02,  9.9087e-01,\n",
       "         -1.1940e-01,  9.9975e-01,  7.7630e-01, -9.9783e-01, -2.1460e-01,\n",
       "          9.9995e-01, -2.7164e-01, -1.0459e-02,  9.8126e-01,  1.9103e-01,\n",
       "          9.8636e-01, -9.9779e-01, -6.7348e-01,  9.9998e-01,  9.9259e-01,\n",
       "          9.8942e-01, -8.8241e-01, -8.9665e-01, -9.9114e-01,  9.8945e-01,\n",
       "         -5.3511e-01,  9.3613e-01,  9.9356e-01, -8.6526e-01, -9.9594e-01,\n",
       "         -2.0523e-02,  9.9995e-01, -6.9221e-01, -1.6612e-01,  9.1809e-01,\n",
       "         -7.9832e-01, -9.9930e-01, -9.9823e-01, -7.0616e-02,  9.9992e-01,\n",
       "          9.6181e-01,  8.4364e-01,  1.7502e-02,  9.9292e-01, -2.3211e-01,\n",
       "          9.9930e-01,  9.3899e-01,  9.6835e-01,  9.9684e-01, -9.9493e-01,\n",
       "         -1.3114e-01,  9.9900e-01, -9.8752e-02, -1.0550e-01, -1.4966e-01,\n",
       "          9.9871e-01,  9.9999e-01, -5.9784e-01, -7.1171e-02,  1.5317e-01,\n",
       "          9.9997e-01, -9.9915e-01, -1.2663e-01, -8.1450e-01, -9.9987e-01,\n",
       "         -2.4093e-01,  9.9936e-01, -9.9468e-01, -9.7782e-02,  9.9644e-01,\n",
       "          2.8157e-01],\n",
       "        [-9.7877e-01, -1.1640e-02, -9.8933e-01, -8.7070e-01, -9.1300e-02,\n",
       "          9.9577e-01,  3.4256e-02,  1.5117e-01,  5.1426e-02,  9.9611e-01,\n",
       "          3.5964e-01,  9.9995e-01, -9.9989e-01,  1.6834e-01,  2.6911e-01,\n",
       "         -1.4158e-03,  9.9965e-01, -2.7595e-01,  9.6046e-01, -9.7178e-01,\n",
       "         -1.0000e+00,  9.6559e-01,  9.9734e-01, -9.4564e-01,  9.9289e-01,\n",
       "          9.9399e-01, -2.8493e-01,  3.9620e-01, -4.8211e-02, -3.9028e-02,\n",
       "         -9.7002e-01,  5.7511e-02,  9.8265e-01, -9.9808e-01, -9.9988e-01,\n",
       "         -9.9925e-01, -2.6689e-01,  6.8777e-01, -4.2485e-01,  3.1118e-01,\n",
       "         -7.5192e-01, -9.6055e-01, -2.5275e-02,  9.9722e-01,  9.9961e-01,\n",
       "          2.7127e-01, -5.8847e-01,  9.9830e-01,  1.9517e-01, -1.0629e-02,\n",
       "         -4.3812e-01, -3.0765e-01,  7.5334e-02,  9.9999e-01, -9.6992e-01,\n",
       "         -6.9579e-01,  9.8855e-01,  9.9941e-01, -3.3934e-01, -9.9465e-01,\n",
       "         -9.9997e-01,  9.9985e-01,  9.9868e-01,  2.9703e-01,  1.1489e-02,\n",
       "          7.1784e-01,  7.6578e-02, -7.7897e-01, -3.2598e-01, -1.2200e-01,\n",
       "          1.9977e-01,  2.3467e-01, -9.6376e-01,  9.9631e-01,  8.2480e-02,\n",
       "         -7.2259e-01,  9.8805e-01, -2.0523e-01,  5.9256e-01,  8.0996e-01,\n",
       "         -9.9220e-01, -7.1287e-02,  6.5008e-01, -1.1160e-01, -1.9300e-01,\n",
       "         -9.7581e-01, -1.3712e-01,  9.9999e-01, -1.9590e-01, -9.9969e-01,\n",
       "          9.9981e-01, -9.8679e-01, -2.5721e-01,  1.9865e-02, -9.9672e-01,\n",
       "         -5.4590e-01,  2.4865e-01,  3.1565e-01,  9.8476e-01,  1.2190e-01,\n",
       "         -9.9756e-01,  4.5187e-01, -9.9943e-01,  8.5184e-01,  4.1513e-01,\n",
       "         -1.1482e-01, -9.9998e-01, -8.7310e-01,  2.2401e-01,  1.4446e-01,\n",
       "         -1.8156e-01,  2.9318e-01,  9.6809e-02,  2.0344e-01, -1.9654e-01,\n",
       "         -2.6662e-03,  9.8341e-01, -7.1460e-01, -9.9779e-01,  1.1122e-01,\n",
       "         -9.8362e-01, -9.9960e-01, -1.6710e-01,  9.6000e-01,  9.8558e-01,\n",
       "          1.1468e-01,  6.9544e-01, -9.9670e-01,  2.7104e-02, -9.6568e-01,\n",
       "         -1.8035e-01,  1.7977e-01,  5.5273e-02,  9.9549e-01, -3.9907e-01,\n",
       "         -9.9941e-01, -9.9954e-01,  9.4146e-01, -7.9957e-01,  4.7080e-02,\n",
       "          9.5218e-01, -2.1630e-01, -7.7462e-01, -8.7813e-01,  9.7288e-01,\n",
       "         -9.8940e-01, -9.9996e-01,  9.9999e-01,  1.0000e+00, -8.2037e-01,\n",
       "          9.9989e-01, -8.6803e-01, -9.9997e-01,  8.5126e-01, -9.9572e-01,\n",
       "         -1.0877e-01,  9.9798e-01,  1.7451e-01, -9.4590e-01,  9.8700e-01,\n",
       "         -9.9999e-01, -1.6120e-01,  9.3268e-01, -1.9773e-01, -9.7897e-01,\n",
       "         -9.4984e-01, -6.0262e-02,  6.3449e-02, -9.9915e-01, -9.6079e-02,\n",
       "         -9.8435e-01,  9.9332e-01,  2.7213e-01, -1.6418e-02,  1.0567e-01,\n",
       "          3.2698e-02,  9.9862e-01, -9.9911e-01, -2.4772e-01, -6.0187e-04,\n",
       "          9.8284e-01,  1.8775e-01, -9.5182e-02, -9.9988e-01,  9.9997e-01,\n",
       "         -8.9494e-01,  9.9993e-01,  9.9993e-01,  5.0565e-03,  6.8385e-01,\n",
       "         -3.1025e-01,  9.9994e-01,  7.2907e-01, -9.9158e-01, -2.1127e-01,\n",
       "          9.9998e-01, -2.4031e-01,  2.8350e-02,  9.9869e-01,  1.8254e-01,\n",
       "          9.9919e-01, -9.9615e-01,  5.1180e-01,  9.9986e-01,  9.3538e-01,\n",
       "          9.5578e-01, -8.9359e-01, -9.8186e-01, -9.7902e-01,  9.9960e-01,\n",
       "         -8.6552e-01,  9.6493e-01,  9.7649e-01, -9.8226e-01, -9.7936e-01,\n",
       "          4.4714e-02,  9.9998e-01, -9.6177e-01,  8.4375e-01,  9.1660e-01,\n",
       "         -9.4539e-01, -9.9976e-01, -9.9324e-01, -3.6352e-02,  9.9956e-01,\n",
       "          5.8774e-01,  6.2184e-01,  1.9156e-02,  9.9830e-01, -4.1248e-02,\n",
       "          9.9966e-01,  8.0737e-01,  9.8685e-01,  9.9996e-01, -9.9813e-01,\n",
       "         -2.4597e-01,  9.9068e-01, -2.9262e-01, -1.2145e-01, -2.0095e-01,\n",
       "          9.9766e-01,  9.9998e-01,  7.8020e-01,  6.9317e-02, -6.4181e-01,\n",
       "          9.9996e-01, -9.9992e-01,  4.1746e-02, -9.6205e-01, -9.9986e-01,\n",
       "         -2.9472e-01,  9.9971e-01, -9.2670e-01, -1.3109e-01,  9.9534e-01,\n",
       "          5.5538e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Poly-Encoder实现\n",
    "\n",
    "\n",
    " <br>\n",
    " \n",
    "---\n",
    "\n",
    "### <font color='orange'>poly-encoder:</font>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src='poly.png' width='600' height='600'/>\n",
    "</div>\n",
    "\n",
    "#### 见Pycharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.课后做业\n",
    "\n",
    "- 【代码实践】1.手动复现BERT。 2.Poly-encoder应用在其他数据集上，尝试复现论文实验结果。\n",
    "- 【思考题】 思考如何改进这个模型？BERT基础+顶层设计。\n",
    "- 【总结】 完成一篇博客，记下完整的学习过程、知识点以及自己的思考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
